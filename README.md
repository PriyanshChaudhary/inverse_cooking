# inverse_cooking
This model allows you to know how a dish came to life. The ingredients, the process, everything that was reqd. to make it from an image of the dish itself.
If you are already an ML learner or even a beginner in this field, you might have thought of how this model was built.
Well the first thing that comes to mind is image recognition of the food and then predicting the dishes on the model trained on a large dataset. 

Congratulations,
if you've thought along these lines you have made a good invesment of your time in this field. But you are half right. Though indeed we did an image prediction on the images, we instead of an entire inage were more focused on the ingredient pipeline.
# OVERVIEW
When you finally go to a restaurant that you always wanted to go, step inside and order that dish that you always dreamt yourself eating, wanted to know how that food came to fruition, what magic was involved in making that fine masterpiece but never had the chance to. Fortunately, we have machine learning for our rescue. In this project, I have introduced a model that runs on a machine learning platform which can help one identify the name and the recipe used in order to make the dish. This machine learning model is based on a theory by making an extension of the retrieval system to a cross-validation embedded system which allows it to extract the ingredient embeddings from an image of the food and identify the correct name & recipe by cross-validating with the Recipe1M dataset. The model then identifies the ingredients and the relative image with the dataset simultaneously to produce the optimum results.

# Implementation
with the help of this model one is able to procure the recipe and name of the dish depicted in the image. In this model, we have produced a method for extracting the details of the dish using two modalities: the ingredients and the image of the food itself. Using these two modalities together, this model is able to achieve the higher threshold of accuracy in comparison to the previously built models.
# Materials and Methods
Due to the failure of previous models in the field of accuracy of ingredient prediction, these food prediction models were not making much progress even with the advancement of high-level algorithms and accuracy in predictive modelling.
 
Instead of predicting the food preparing process without an intermediary in between to process the minute details, this model makes use of a pipeline containing the necessary parameters for the analysis and prediction of the ingredients and the recipe. As depicted in the figure above, instead of thinking of all ingredients present together as a set, this model actually considers them as a list. After all, one can presume that the ingredients are ordered and always put into the dish sequentially according to the recipe. Hence, to include that facet into our approach this project used both the list and set form of ingredients and trained the model over both parameters.
	In conclusion, what one can do is take both the image and the ingredient embeddings in the input image and cross-validate them with the database to produce better results. This approach works much better as compared to directly predicting the recipe just from the image. So, these two embeddings are used as classifier for the input image by a process decoder. The first phase is the optical features taken from an image of the food and the second phase is mainly geared towards the extraction of ingredients from the image.
	Our first job is to extract the image depiction of the dish and use this along with the extracted ingredient embeddings to predict our first instruction- the name of the dish. The image embeddings can be extracted using the ResNet-50 encoder. On the other hand, the embeddings for the ingredients in the dish can be done by a single mapping layer converting the ingredients to a vector. Now what one has to do is to create a transformer model that is able to use self-attention on layers to improve the quality of recipe prediction. In this one, one can use two attention layers with first one applying self-attention on the result that were generated in the step before while the second layer just refines the previous layer in the transformer model. In the end of the transformer, one has used a max-pool layer to concatenate the huge images into smaller relative counterparts while the max-entropy is done to give probabilistic distributions of the different candidate ingredients selected.  
	The ingredient decoder is the next phase of the image analysis. As it was mentioned in the start of the report that the previously built models had very low accuracy on recipe inversion because they take the entire ingredients as a set which leads to them inaccurately predicting the title of the dishes who have similar component ingredients. Therefore, the correct approach would be to address the ingredients into a list instead of a set and then using that ordered data one could conclude the specialities of the dish. This model will consider these inputs along in the auto-regressive models alongside the transformer model. Though the transformer model makes one able to consider both the list and set parameters of the ingredients but another issue rises up in concern with the ordering of the ingredients as this formulation becomes faulty for being ordered even when that is not required.
